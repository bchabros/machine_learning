{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c8c506-a5df-404f-a364-d3409df32c8e",
   "metadata": {},
   "source": [
    "# DQN on custom ENV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc2c19a-7442-42de-a428-89e685773d2a",
   "metadata": {},
   "source": [
    "remember to install your own env!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49067031-0a1e-4ab7-a119-e695053ca2a0",
   "metadata": {},
   "source": [
    "## Import and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af5dbbbc-50cb-446d-a66d-97499489e75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # to transform the image in the Processor\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "# CNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Keras-RL \n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40c79cbe-9f1c-43a3-a8da-43bc44e11c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.7.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('snake:snake-v0')\n",
    "nb_actions = env.action_space.n\n",
    "nb_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d62d39b-c0e4-480a-943b-cd76947ad159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use shape 84x84 and window length 4 (timestep of 4 consecutive frames)\n",
    "IMG_SHAPE = (84, 84)\n",
    "WINDOW_LENGTH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "741c61b6-4310-4e17-9cca-41b917c8f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor(Processor):\n",
    "    \n",
    "    def process_observation(self, observation):\n",
    "        \n",
    "        img = Image.fromarray(observation) # convert from numpy array to PIL Image\n",
    "        img = img.resize(IMG_SHAPE) # resize image\n",
    "        img = img.convert('L') # convert to grayscale\n",
    "        img = np.array(img) # convert the image back to a numpy array\n",
    "        \n",
    "        return img.astype('uint8') # optimize training time for less memory\n",
    "    \n",
    "    def process_state_batch(self, batch):\n",
    "        \n",
    "        processed_batch = batch.astype('float32')/255.0 # divded by 255 to compress it into [0, 1]\n",
    "        \n",
    "        return processed_batch\n",
    "    \n",
    "    def process_reward(self, reward):\n",
    "        \n",
    "        return np.clip(reward, -1.0, 1.0) # normalized reward [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa212c5b-6e9b-43f8-bf54-5d22799991fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 84, 84)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define input shape 4 x 84 x 84\n",
    "input_shape = (WINDOW_LENGTH, IMG_SHAPE[0], IMG_SHAPE[1])\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94f34f7-7aa5-4c77-91a6-df42f4a6f18d",
   "metadata": {},
   "source": [
    "## Constructing the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f77c2a0-67dd-4ce0-b451-0f53bd3a3f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Chabi/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "permute (Permute)            (None, 84, 84, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 20, 20, 32)        8224      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 9, 64)          32832     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,686,180\n",
      "Trainable params: 1,686,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Convolution2D input_shape should be (Batch, 84, 84, 4)\n",
    "model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
    "\n",
    "model.add(Convolution2D(filters=32,\n",
    "                        kernel_size=(8, 8),\n",
    "                        strides=(4, 4),\n",
    "                        kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(filters=64,\n",
    "                        kernel_size=(4, 4),\n",
    "                        strides=(2, 2),\n",
    "                        kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(filters=64,\n",
    "                        kernel_size=(3, 3),\n",
    "                        strides=(1, 1),\n",
    "                        kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# output layer actions = Q(s, a)\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc85a2a4-ac2c-4ab2-bcc6-64d6e52437f3",
   "metadata": {},
   "source": [
    "## Setting up the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c50eb7a-9514-4b13-ab88-1ca6f5023d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define the memory\n",
    "memory = SequentialMemory(limit=1_000_000,\n",
    "                          window_length=WINDOW_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bb74962-2be6-4ee9-8de1-53d7f9c91d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define processor\n",
    "processor = ImageProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bab074c9-5300-4f9d-b03a-8d2dfb5f08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a LinearAnnealedPolicy to implement the epsilon greedy action selection with decaying epsilon.\n",
    "# As we need to train for at least a million steps, we set the number of steps to 1,000,000\n",
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(),\n",
    "                              nb_steps=1_000_000,\n",
    "                              attr='eps',\n",
    "                              value_max=1.0,\n",
    "                              value_min=-1.0,\n",
    "                              value_test=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6512f2da-283f-4ce3-a26f-8ee1771fa290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define agent and compile it. the agent is define with add train_interval=4, we train every 4th step\n",
    "# besides we clip delta (the error) to 1 both, clipping and train_interval often increase the result\n",
    "\n",
    "dqn = DQNAgent(model=model,\n",
    "               nb_actions=nb_actions,\n",
    "               policy=policy,\n",
    "               memory=memory,\n",
    "               processor=processor,\n",
    "               nb_steps_warmup=50_000,\n",
    "               gamma=0.99,\n",
    "               target_model_update=10_000,\n",
    "               train_interval=4,\n",
    "               delta_clip=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ca67fa5-4c06-43af-ad04-f38f1a6dd476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 23:24:47.640203: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-14 23:24:47.641114: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 10. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "dqn.compile(optimizer=Adam(learning_rate=0.00025),\n",
    "            metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "835983e8-cd0e-415e-8cf3-af1a92070cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Chabi/Documents/reinforcment_learning/Codes/10_ENV'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d5bcefb-9409-4dc8-a8c3-72a3fa66216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving weights as my train\n",
    "weights_filename = 'test_bartek_dqn_snake_weights.h5f'\n",
    "checkpoint_weights_filename = 'test_dqn_bartek_' + 'snake' + '_weights_{step}.h5f'\n",
    "checkpoint_callback = ModelIntervalCheckpoint(checkpoint_weights_filename, interval=100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9495fb6e-591d-4b7f-8117-92d5833930b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1500000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "100000/100000 [==============================] - 35446s 354ms/step - reward: -0.0200\n",
      "2211 episodes - episode_reward: -0.905 [-1.000, 1.000] - loss: 0.003 - mae: 0.178 - mean_q: 0.239 - mean_eps: 0.850 - score: 0.073\n",
      "\n",
      "Interval 2 (100000 steps performed)\n",
      "100000/100000 [==============================] - 7575s 76ms/step - reward: -0.0117\n",
      "1522 episodes - episode_reward: -0.766 [-1.000, 2.000] - loss: 0.002 - mae: 0.353 - mean_q: 0.486 - mean_eps: 0.700 - score: 0.165\n",
      "\n",
      "Interval 3 (200000 steps performed)\n",
      "100000/100000 [==============================] - 7565s 76ms/step - reward: -0.0031\n",
      "1628 episodes - episode_reward: -0.189 [-1.000, 5.000] - loss: 0.004 - mae: 0.584 - mean_q: 0.803 - mean_eps: 0.500 - score: 0.513\n",
      "\n",
      "Interval 4 (300000 steps performed)\n",
      "100000/100000 [==============================] - 7700s 77ms/step - reward: 0.0084\n",
      "1707 episodes - episode_reward: 0.493 [-1.000, 7.000] - loss: 0.008 - mae: 0.886 - mean_q: 1.228 - mean_eps: 0.300 - score: 0.986\n",
      "\n",
      "Interval 5 (400000 steps performed)\n",
      "100000/100000 [==============================] - 7781s 78ms/step - reward: 0.0215\n",
      "988 episodes - episode_reward: 2.180 [-1.000, 13.000] - loss: 0.013 - mae: 1.270 - mean_q: 1.768 - mean_eps: 0.100 - score: 2.230\n",
      "\n",
      "Interval 6 (500000 steps performed)\n",
      "100000/100000 [==============================] - 7653s 77ms/step - reward: 0.0274\n",
      "497 episodes - episode_reward: 5.519 [0.000, 15.000] - loss: 0.016 - mae: 1.680 - mean_q: 2.342 - mean_eps: -0.100 - score: 4.076\n",
      "\n",
      "Interval 7 (600000 steps performed)\n",
      "100000/100000 [==============================] - 7731s 77ms/step - reward: 0.0321\n",
      "434 episodes - episode_reward: 7.385 [0.000, 20.000] - loss: 0.018 - mae: 2.051 - mean_q: 2.870 - mean_eps: -0.300 - score: 5.943\n",
      "\n",
      "Interval 8 (700000 steps performed)\n",
      "100000/100000 [==============================] - 7758s 78ms/step - reward: 0.0322\n",
      "343 episodes - episode_reward: 9.382 [0.000, 22.000] - loss: 0.018 - mae: 2.288 - mean_q: 3.216 - mean_eps: -0.500 - score: 7.401\n",
      "\n",
      "Interval 9 (800000 steps performed)\n",
      "100000/100000 [==============================] - 7808s 78ms/step - reward: 0.0365\n",
      "357 episodes - episode_reward: 10.202 [0.000, 23.000] - loss: 0.018 - mae: 2.527 - mean_q: 3.568 - mean_eps: -0.700 - score: 7.788\n",
      "\n",
      "Interval 10 (900000 steps performed)\n",
      "100000/100000 [==============================] - 7802s 78ms/step - reward: 0.0374\n",
      "323 episodes - episode_reward: 11.560 [1.000, 27.000] - loss: 0.020 - mae: 2.799 - mean_q: 3.961 - mean_eps: -0.900 - score: 8.796\n",
      "\n",
      "Interval 11 (1000000 steps performed)\n",
      "100000/100000 [==============================] - 7839s 78ms/step - reward: 0.0388\n",
      "317 episodes - episode_reward: 12.221 [0.000, 28.000] - loss: 0.021 - mae: 3.008 - mean_q: 4.268 - mean_eps: -1.000 - score: 9.430\n",
      "\n",
      "Interval 12 (1100000 steps performed)\n",
      "100000/100000 [==============================] - 7895s 79ms/step - reward: 0.0396\n",
      "283 episodes - episode_reward: 14.011 [0.000, 29.000] - loss: 0.023 - mae: 3.217 - mean_q: 4.585 - mean_eps: -1.000 - score: 10.645\n",
      "\n",
      "Interval 13 (1200000 steps performed)\n",
      " 67669/100000 [===================>..........] - ETA: 44:42 - reward: 0.0426"
     ]
    }
   ],
   "source": [
    "dqn.fit(env,\n",
    "        nb_steps=1_500_000,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        log_interval=100_000,\n",
    "        visualize=False)\n",
    "\n",
    "#after training is done, we save the final weights one more time\n",
    "dqn.save_weights(weights_filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "614f1c13-d129-40a9-83bf-e4975b3d4a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fe6136bee10> and <tensorflow.python.keras.layers.core.Permute object at 0x7fe6136be9d0>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fe5b0439790> and <tensorflow.python.keras.layers.core.Activation object at 0x7fe6136d3190>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fe5b032d550> and <tensorflow.python.keras.layers.core.Activation object at 0x7fe5b032d990>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7fe5b0312750> and <tensorflow.python.keras.layers.core.Flatten object at 0x7fe5b0320690>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7fe5d0991bd0> and <tensorflow.python.keras.layers.core.Activation object at 0x7fe5b029ef10>).\n"
     ]
    }
   ],
   "source": [
    "# Load weights\n",
    "model.load_weights('snake_weights/dqn_snake_weights_1200000.h5f')\n",
    "\n",
    "memory = SequentialMemory(limit=1_000_000,\n",
    "                          window_length=WINDOW_LENGTH)\n",
    "\n",
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(),\n",
    "                              nb_steps=1_000_000,\n",
    "                              attr='eps',\n",
    "                              value_max=1.0,\n",
    "                              value_min=-1.0,\n",
    "                              value_test=0.05)\n",
    "\n",
    "dqn = DQNAgent(model=model,\n",
    "               nb_actions=nb_actions,\n",
    "               policy=policy,\n",
    "               memory=memory,\n",
    "               processor=processor,\n",
    "               nb_steps_warmup=50_000,\n",
    "               gamma=0.99,\n",
    "               target_model_update=10_000,\n",
    "               train_interval=4,\n",
    "               delta_clip=1)\n",
    "\n",
    "dqn.compile(optimizer=Adam(learning_rate=0.00025),\n",
    "            metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "49c0b44b-e22f-48d7-a7e5-28289ae388ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.sleep=0.2 # doesn't move increadibly fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b54fbd5-d088-4763-aa95-30dc9b4cac1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 1 episodes ...\n",
      "Episode 1: reward: 4.000, steps: 116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe6138c05d0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.test(env,\n",
    "         nb_episodes=1,\n",
    "         visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76048182-40bf-4e9f-8c7a-6da6d01fd971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
