{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b95fe9c-b6b0-475c-acad-3f179b87672b",
   "metadata": {},
   "source": [
    "# DQN with Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfae6c43-191a-4473-b47a-d2414f8d853f",
   "metadata": {},
   "source": [
    "## Imports and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c393b1-8a9e-4040-8eaa-d5ab5441d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "# Convolutional Backbone Network\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Keras-RL\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84db212a-7ba6-4abf-b5fa-c03db3fa5ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.7.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from gym.utils import play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "483b226b-9435-44f8-a986-3c3dd8986982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"BreakoutDeterministic-v4\", render_mode='human') #https://github.com/openai/gym/issues/1280\n",
    "nb_action = env.action_space.n\n",
    "nb_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66475004-bda1-4b33-be5d-09b3740068a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use shape 84x84 and window length 4 (timestep of 4 consecutive frames)\n",
    "\n",
    "IMG_SHAPE = (84, 84) \n",
    "WINDOW_LENGTH = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea9c1a3-65ce-432a-9424-325471a21867",
   "metadata": {},
   "outputs": [],
   "source": [
    "play.play(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f9da7e4-4c01-4707-adce-767e582796d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on those settings we create our processor. It is the same processor as in the last notebook, \n",
    "# with the addition that it standardizes the data into the [0, 1] intervall which often decreases \n",
    "# the necessary training time. \n",
    "# We perform this standardization routine in the process_state_batch function, \n",
    "# which is only executed on the current batch and not on the complete replay memory \n",
    "# which decreases RAM usage by a factor of 4. Additionally we clip the reward \n",
    "# in the intervall [-1, 1] which might speed up the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01044eef-d0a9-4808-ab55-3c0b96beda0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor(Processor):\n",
    "    \n",
    "    def process_observation(self, observation):\n",
    "        img = Image.fromarray(observation) # convert from numpy array to PIL Image\n",
    "        img = img.resize(IMG_SHAPE) # resize the image\n",
    "        img = img.convert('L') # convert it to grayscale\n",
    "        img = np.array(img) # convert the image back to a numpy array\n",
    "        \n",
    "        return img.astype('uint8') # optimize training time less memory\n",
    "    \n",
    "    def process_state_batch(self, batch):\n",
    "        processsed_batch = batch.astype('float32')/255.0 # divided by 255 to compress it into [0, 1]\n",
    "        return processsed_batch\n",
    "    \n",
    "    def process_reward(self, reward):\n",
    "        return np.clip(reward, -1.0, 1.0) # normalized reward [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e153ea18-0a31-44e5-9e46-f66c7cb688ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 84, 84)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define input shape 4 x 84 x 84\n",
    "input_shape = (WINDOW_LENGTH, IMG_SHAPE[0], IMG_SHAPE[1])\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f8eae8-7f0f-40ed-ae9f-6816e41a2928",
   "metadata": {},
   "source": [
    "## Constructing the Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df98ab5-a296-4b21-b168-fd48d5f71a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution2D input_shape should be (Batch, 84, 84, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06008256-1503-427c-b9ec-10cd3a7f692f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Chabi/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "permute (Permute)            (None, 84, 84, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 20, 20, 32)        8224      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 9, 64)          32832     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,686,180\n",
      "Trainable params: 1,686,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# permutation on input data swaping data, change places\n",
    "#https://keras.io/api/layers/reshaping_layers/permute/\n",
    "model.add(Permute((2, 3, 1), input_shape=input_shape)) \n",
    "\n",
    "model.add(Convolution2D(filters=32, \n",
    "                        kernel_size=(8,8), \n",
    "                        strides=(4,4), \n",
    "                        kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Convolution2D(filters=64, \n",
    "                        kernel_size=(4,4), \n",
    "                        strides=(2,2), \n",
    "                        kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(filters=64, \n",
    "                        kernel_size=(3,3), \n",
    "                        strides=(1,1), \n",
    "                        kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# output layer actions ---> Q(s, a)\n",
    "model.add(Dense(nb_action))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f7a09-5af9-4f8a-a6f4-f8fabdbbf492",
   "metadata": {},
   "source": [
    "## Setting up the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b216638-5771-4afd-8cb0-739d3ee0136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define the memory. We use again the SequentialMemory, but this time with window_lenght = 4\n",
    "memory = SequentialMemory(limit=1_000_000,\n",
    "                          window_length=WINDOW_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07290c4f-3bb9-4e8a-a213-f39c9cfc6c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define processor\n",
    "processor = ImageProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c14dfc7-10b7-44c9-9c20-990f8e7ca9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use again a LinearAnnealedPolicy to implement the epsilon greedy action selection with decaying epsilon.\n",
    "# As we need to train for at least a million steps, we set the number of steps to 1,000,000\n",
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(),\n",
    "                              nb_steps=1_000_000,\n",
    "                              attr='eps',\n",
    "                              value_max=1.0,\n",
    "                              value_min=-1.0,\n",
    "                              value_test=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a424b9f-df6e-4753-ad60-bd8b2b96c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define agent and compile it. The agent is defined in the same way in the previous lectures with add \n",
    "# train_interval=4, we train on every 4th step\n",
    "# besides we clip delta (the error) to 1 \n",
    "# Both, clipping and train_interval ofren increase the result\n",
    "\n",
    "dqn = DQNAgent(model=model,\n",
    "               nb_actions=nb_action,\n",
    "               policy=policy,\n",
    "               memory=memory,\n",
    "               processor=processor,\n",
    "               nb_steps_warmup=50_000,\n",
    "               gamma=.99,\n",
    "               target_model_update=10_000,\n",
    "               train_interval=4,\n",
    "               delta_clip=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a0f6681-5aec-4edd-b86b-4f28385101d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 18:41:45.288736: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-12 18:41:45.289529: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 10. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "dqn.compile(optimizer=Adam(learning_rate=0.00025),\n",
    "            metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99c1b922-de44-48a5-aca2-0abeb0c2deba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Chabi/Documents/reinforcment_learning/Codes/09_DQN_Images'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f68c7440-5df1-4054-ad0c-d1e53c08ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_filenamne = 'DQN_B0.h5f'\n",
    "checkpoint_filename = 'DQN_CHECKPOINT.h5f'\n",
    "\n",
    "checkpoint_callback = ModelIntervalCheckpoint(checkpoint_filename,\n",
    "                                              interval=100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f70f29c1-5a76-4eb1-b4eb-d1d674b0afa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa7b8308990> and <tensorflow.python.keras.layers.core.Permute object at 0x7fa768a82090>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa768ac2f10> and <tensorflow.python.keras.layers.core.Activation object at 0x7fa768a82c90>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa7b8456390> and <tensorflow.python.keras.layers.core.Activation object at 0x7fa7b8430f10>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7fa7b84a8a50> and <tensorflow.python.keras.layers.core.Flatten object at 0x7fa7b8477810>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7fa7b84d7dd0> and <tensorflow.python.keras.layers.core.Activation object at 0x7fa7b84d7ed0>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa78cb14610>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the weights\n",
    "model.load_weights(\"/Users/Chabi/Documents/reinforcment_learning/Codes/09_DQN_Images/weights/dqn_BreakoutDeterministic-v4_weights_900000.h5f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71b553a1-b497-471f-9c5f-351210905135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the policy to start with smaller epsilon\n",
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(),\n",
    "                              nb_steps=1_000_000,\n",
    "                              attr='eps',\n",
    "                              value_max=0.2, # for this script\n",
    "                              value_min=-1.0,\n",
    "                              value_test=0.05)\n",
    "\n",
    "\n",
    "# initialize the DQNagent with the new model and update policy and compile it\n",
    "dqn = DQNAgent(model=model,\n",
    "               nb_actions=nb_action,\n",
    "               policy=policy,\n",
    "               memory=memory,\n",
    "               processor=processor,\n",
    "               nb_steps_warmup=50_000,\n",
    "               gamma=.99,\n",
    "               target_model_update=10_000,\n",
    "               train_interval=4,\n",
    "               delta_clip=1)\n",
    "\n",
    "\n",
    "dqn.compile(optimizer=Adam(learning_rate=0.00025),\n",
    "            metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2d7d0-1902-4875-9e9e-9600ab028cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "500/500 [==============================] - 19s 38ms/step - reward: 0.0180\n",
      "Interval 2 (500 steps performed)\n",
      "170/500 [=========>....................] - ETA: 11s - reward: 0.0176"
     ]
    }
   ],
   "source": [
    "# test if everything is okay \n",
    "dqn.fit(env,\n",
    "        nb_steps=1000,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        log_interval=500,\n",
    "        visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7ea6f-b858-41cf-9508-7df50d78b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dqn.test(env,\n",
    "#         nb_episodes=1,\n",
    "#         visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a4b55e-97a2-4cf3-9b7a-7e1ac4144c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749016cf-8a3e-42e3-a3be-47ede199dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"/Users/Chabi/Documents/reinforcment_learning/Codes/09_DQN_Images/weights/dqn_BreakoutDeterministic-v4_weights_1200000.h5f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ab595-4dc7-4536-976a-8e5b0bb69d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = EpsGreedyQPolicy(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00369d5-a680-43d6-8da9-d0b7043d7b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DQNAgent(model=model,\n",
    "               nb_actions=nb_action,\n",
    "               policy=policy,\n",
    "               memory=memory,\n",
    "               processor=processor)\n",
    "\n",
    "dqn.compile(optimizer=Adam(learning_rate=0.00025),\n",
    "            metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b6f4f9-bb50-4cc4-a7f2-4eb90de692e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.test(env, nb_episodes=5, visualize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
